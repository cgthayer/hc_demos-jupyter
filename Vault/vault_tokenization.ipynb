{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize Data with Transform Secrets Engine\n",
    "\n",
    "Learn how the Transform secrets engine's data tokenization works to provide\n",
    "  maximum resistance to data being compromised.\n",
    "\n",
    "> **NOTE:** Transform secrets engine requires [Vault Enterprise Advanced Data\n",
    "Protection (ADP)](https://www.hashicorp.com/products/vault/pricing/) license. To\n",
    "explore Vault Enterprise features, you can sign up for a free 30-day trial from\n",
    "[here](http://vaultproject.io/trial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Challenge\n",
    "\n",
    "When encrypting sensitive data, preservation of the original data format or\n",
    "length may be required to meet certain industry standards such as\n",
    "[HIPAA](https://www.hhs.gov/hipaa/index.html) or\n",
    "[PCI](https://www.pcisecuritystandards.org/). To fulfill this requirement, the\n",
    "transform secrets engine performs [format preserving encryption\n",
    "(FPE)](/tutorials/vault/transform?in=vault/adp).\n",
    "\n",
    "There are organizations that care more about the irreversibility of the\n",
    "tokenized data and not so much about preserving the original data format.\n",
    "Therefore, the transform secrets engine's FPE transformation may not meet the\n",
    "governance, risk and compliance (GRC) strategy they are looking for due to the\n",
    "use of reversible cryptography to perform FPE.\n",
    "\n",
    "Tokenization replaces sensitive data with unique values (tokens) that are unrelated to the original value.  Those tokens cannot risk exposing the plaintext satisfying the PCI-DSS guidance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Transit vs Transform Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| FEATURE | TRANSIT | TRANSFORM FPE | TRANSFORM MASKING | TRANSFORM TOKENIZATION\n",
    "| ---  | :-: | :-: | :-: | :-: |\n",
    "| - | Two Way | Two Way | One Way | One Way (by default)\n",
    "| Stateful | No | No | No | Yes <br>(internal/external)\n",
    "| Format Preserved | No | Yes | Yes | No\n",
    "| Custom Metadata | No | No | No | Yes\n",
    "| Algorithm(s) | Multiple | NIST FF3-1 | N/A (pseudonymous) | AES256-GCM96\n",
    "| Key Rotation | Yes | N/A | N/A | Yes\n",
    "| Deduplication | Optional <br>(w/convergent encryption) | Optional <br>(w/ supplied tweak) | Yes | No\n",
    "| Batch Input Support | Yes | Yes | Yes | Yes\n",
    "| Entropy Augmentation Support | Yes | Yes | Yes | Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "Transform secrets engine has a data transformation method to **tokenize**\n",
    "sensitive data stored outside of Vault. Tokenization replaces sensitive data\n",
    "with unique values (tokens) that are unrelated to the original value in any\n",
    "algorithmic sense. Therefore, those tokens cannot risk exposing the plaintext\n",
    "satisfying the PCI-DSS guidance.\n",
    "\n",
    "<img alt=Tokenization src=https://learn.hashicorp.com/img/vault/vault-tokenization-1.png width=640>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Characteristics of the tokenization transformation:\n",
    "\n",
    "- **Non-reversible identification:** Protect data pursuant to requirements for\n",
    "  data irreversibility (PCI-DSS, GDPR, etc.)\n",
    "\n",
    "- **Integrated Metadata:** Supports metadata for identifying data type and\n",
    "  purpose\n",
    "\n",
    "- **Extreme scale and performance:** Support for performantly managing billions\n",
    "  of tokens across clouds as well as on-premise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To perform the tasks described in this tutorial you need to have:\n",
    "\n",
    "* Running Vault Enterprise **v1.6** or later with Advanced Data Protection module license\n",
    "  * See [Start Vault Server](./100-Setup-Vault.ipynb)\n",
    "  * If you are using cloning this repo, then the license file needs to be placed in `hc_demos-jupyter/HashiStack/vault/config/vault.hclic`\n",
    "* Docker\n",
    "\n",
    "> **NOTE:** To explore Vault Enterprise features, you can [sign up for a free\n",
    "30-day trial](http://vaultproject.io/trial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customize the values for `VAULT_ADDR` and `VAULT_TOKEN` if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export CONSUL_DC=west CONSUL_DC_2=east\n",
    "export COMPOSE_PROJECT_NAME=hashi\n",
    "export COMPOSE_FILE=docker-compose.yml:docker-compose-hashi.yml:docker-compose-hashi-dev.yml:docker-compose-proxy.yml\n",
    "\n",
    "export VAULT_ADDR=http://127.0.0.1:8200\n",
    "export VAULT_TOKEN=root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart Vault Cluster\n",
    "pushd ../HashiStack\n",
    "docker-compose \\\n",
    "  up --force-recreate -d \\\n",
    "  vault_s1\n",
    "popd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm Vault Enterprise is up and licensed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vault status\n",
    "vault read sys/license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ../HashiStack/vault/config/vault.hclic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Policy requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE:** For the purpose of this tutorial, you can use `root` token to work\n",
    "with Vault. However, it is recommended that root tokens are only used for just\n",
    "enough initial setup or in emergencies. As a best practice, use tokens with\n",
    "appropriate set of policies based on your role in the organization.\n",
    "\n",
    "To perform all tasks demonstrated in this tutorial, your policy must include the\n",
    "following permissions:\n",
    "\n",
    "```hcl\n",
    "# Work with transform secrets engine\n",
    "path \"transform/*\" {\n",
    "  capabilities = [ \"create\", \"read\", \"update\", \"delete\", \"list\" ]\n",
    "}\n",
    "\n",
    "# Enable secrets engine\n",
    "path \"sys/mounts/*\" {\n",
    "  capabilities = [ \"create\", \"read\", \"update\", \"delete\", \"list\" ]\n",
    "}\n",
    "\n",
    "# List enabled secrets engine\n",
    "path \"sys/mounts\" {\n",
    "  capabilities = [ \"read\", \"list\" ]\n",
    "}\n",
    "```\n",
    "\n",
    "If you are not familiar with policies, complete the\n",
    "[policies](https://learn.hashicorp.com/tutorials/vault/policies) tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup the Transform secrets engine\n",
    "\n",
    "Create a role named, `mobile-pay` which is attached to `credit-card`\n",
    "transformation. The tokenized value has a fixed maximum time-to-live (TTL) of 24\n",
    "hours.\n",
    "\n",
    "Sample flow\n",
    "\n",
    "<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/How_mobile_payment_tokenization_works.png/640px-How_mobile_payment_tokenization_works.png >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable the Transform secrets engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vault secrets enable transform || true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roles, Transformations, Templates and Alphabets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a role named `mobile-pay` which is attached to transformation named `credit-card`.  \n",
    "\n",
    "<img src=https://learn.hashicorp.com/img/vault/vault-tokenization-2.png width=640 >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vault write transform/role/mobile-pay transformations=credit-card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The role is created but the `credit-card` transformation does not exist, yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a transformation named `credit-card`, which sets the generated token's time-to-live (TTL) to 24 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vault write transform/transformation/credit-card \\\n",
    "  type=tokenization \\\n",
    "  max_ttl=24h \\\n",
    "  allowed_roles=mobile-pay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The `max_ttl` is an optional parameter which allows you to control how long the token should stay valid.\n",
    "* **NOTE:** Set the `allowed_roles` parameter to a wildcard (`*`) to allow all roles or with globs at the end for pattern matching (e.g. `mobile-*`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display details about the `credit-card` transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vault read transform/transformations/tokenization/credit-card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Output\n",
    "```\n",
    "Key              Value\n",
    "---              -----\n",
    "allowed_roles    [mobile-pay]\n",
    "mapping_mode     default\n",
    "max_ttl          0s\n",
    "stores           [builtin/internal]\n",
    "templates        <nil>\n",
    "type             tokenization\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Notice that the `type` is set to `tokenization`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the secrets engine is configured, this can be used to encode and decode input values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vault write transform/encode/mobile-pay value=1111-2222-3333-4444 \\\n",
    "  ttl=8h \\\n",
    "  metadata=\"type=Amex\" \\\n",
    "  metadata=\"organization=HashiCorp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vault write transform/encode/mobile-pay -format=json value=1111-2222-3333-4444 \\\n",
    "  transformation=credit-card \\\n",
    "  ttl=8h \\\n",
    "  metadata=\"type=Amex\" \\\n",
    "  metadata=\"organization=HashiCorp\" \\\n",
    "  metadata=\"Purpose=Travel\" \\\n",
    "  | tee /tmp/tokenization.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ttl` value is an optional parameter. Remember that the `max_ttl` was set to 24 hours when you created the `credit-card` transformation. You can overwrite that value to make the token's TTL to be shorter.\n",
    "\n",
    "The output displays the encoded value.\n",
    "\n",
    "```shell\n",
    "Key              Value\n",
    "---              -----\n",
    "encoded_value    eRwUjS2L9dnBpuvRKGPvEq3399sm41GGXikoh1sNKivXxeyrej9vp2quuCULqSPpz7UTLgmtM\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode some input value using the /decode endpoint with a named role:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the generated token value in a `MY_TOKEN` environment variable for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export MY_ENCODED_CCN=$(jq -r .data.encoded_value /tmp/tokenization.out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the metadata of the token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vault write transform/metadata/mobile-pay value=$MY_ENCODED_CCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `expiration_time` is displayed. Since you have overwritten the `max_ttl`, the `ttl` is set to 8 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate the token value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vault write transform/validate/mobile-pay value=$MY_ENCODED_CCN transformation=credit-card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate that the credit card number has been tokenized already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vault write transform/tokenized/mobile-pay value=1111-2222-3333-4444 transformation=credit-card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the original plaintext credit card value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vault write transform/decode/mobile-pay value=$MY_ENCODED_CCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Output\n",
    "\n",
    "```shell\n",
    "Key              Value\n",
    "---              -----\n",
    "decoded_value    1111-2222-3333-4444\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup external token storage\n",
    "Tokenization is a stateful procedure to facilitate mapping between tokens and various cryptographic values.  This could put a lot of load on the Vault's storage backend.  You have an option to use external storage to presist data for tokenization tranformation.\n",
    "\n",
    "<img src=\"https://learn.hashicorp.com/img/vault/vault-tokenization-3.png\" width=640 >\n",
    "\n",
    "To demonstrate, run a PostgreSQL database. \n",
    "Create a new transformation, named \"passport\", which uses this PostgreSQL as its storage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike format preserving encryption (FPE) transformation, tokenization is a\n",
    "stateful procedure to facilitate mapping between tokens and various\n",
    "cryptographic values (one way HMAC of the token, encrypted metadata, etc.)\n",
    "including the encrypted plaintext itself which must be persisted.\n",
    "\n",
    "At scale, this could put a lot of additional load on the Vault's storage\n",
    "backend. To avoid this, you have an option to use external storage to persist\n",
    "data for tokenization transformation.\n",
    "\n",
    "-> **NOTE:** Currently, PostgreSQL and MySQL are supported as external storage \n",
    "for tokenization.\n",
    "\n",
    "To demonstrate, run a PostgreSQL database in a Docker container. Create a new\n",
    "transformation named, \"passport\" which uses this PostgreSQL as its storage\n",
    "rather than using the Vault's storage backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://learn.hashicorp.com/img/vault/vault-tokenization-3.png\" width=640 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run [PostgreSQL Docker image](https://hub.docker.com/_/postgres) in a\n",
    "container.\n",
    "\n",
    "Start a `postgres` instance which listens to port `5432`, and the superuser\n",
    "(`root`) password is set to `rootpassword`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export POSTGRES_USER=root\n",
    "export POSTGRES_PASSWORD=rootpassword\n",
    "\n",
    "pushd ../HashiStack && \\\n",
    "docker-compose \\\n",
    "  up --force-recreate -d \\\n",
    "  db && \\\n",
    "popd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the postgres container is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker ps --format \"table {{.ID}}\\t{{.Image}}\\t{{.Names}}\\t{{.Ports}}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "CONTAINER ID        IMAGE            ...         PORTS                    NAMES\n",
    "befcf913da91        postgres         ...         0.0.0.0:5432->5432/tcp   postgres\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Create a new role, \"global-id\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vault write transform/role/global-id transformations=passport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Success! Data written to: transform/role/global-id\n",
    "```\n",
    "\n",
    "2.  Create a store which points to the postgres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vault write transform/stores/postgres \\\n",
    "      type=sql \\\n",
    "      driver=postgres \\\n",
    "      supported_transformations=tokenization \\\n",
    "      connection_string=\"postgresql://{{username}}:{{password}}@db/root?sslmode=disable\" \\\n",
    "      username=root \\\n",
    "      password=rootpassword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vault read transform/stores/postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  Create a schema in postgres to store tokenization artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vault write transform/stores/postgres/schema transformation_type=tokenization \\\n",
    "       username=root password=rootpassword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.  Create a new transformation named, \"passport\" which points to the postgres\n",
    "    store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vault write transform/transformations/tokenization/passport \\\n",
    "       allowed_roles=global-id stores=postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Verify that there are no entries via the `postgres` container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker exec -it postgres psql -U root -c \"select * from tokens;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "storage_token | key_version | ciphertext | encrypted_metadata | fingerprint | expiration_time\n",
    "---------------+-------------+------------+--------------------+-------------+-----------------\n",
    "(0 rows)\n",
    "```\n",
    "\n",
    "6. Encode some test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vault write transform/encode/global-id \\\n",
    "       transformation=passport \\\n",
    "       value=\"123456789\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example output:**\n",
    "\n",
    "```plaintext\n",
    "Key              Value\n",
    "---              -----\n",
    "encoded_value    Q4tYgFXHxUS3PnQLiUnyH2JfGeEZQDFXMMaFXLU6MZfiix1tjqwgNX\n",
    "```\n",
    "\n",
    "1.  From the postgres container, check the data entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker exec -it postgres psql -U root -c \"select * from tokens;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example output:**\n",
    "\n",
    "```shell\n",
    " storage_token        | key_version |       ciphertext          | encrypted_metadata | ...\n",
    "--------------------------+-------------+---------------------------+--------------------+-...\n",
    "\\x128aa3c24699...snip... |           1 | \\x1ee7cc3505e31...snip... |                    | ...\n",
    "(1 row)\n",
    "```\n",
    "\n",
    "As you encode more data, the table entry grows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Transformation secrets engine introduced tokenization transformation feature\n",
    "which replaces sensitive data with unique value (token) that are unrelated to\n",
    "the original value in any algorithmic sense. This can help organizations to meet\n",
    "certain industry standards.\n",
    "\n",
    "If retaining the original data format is important, refer to the [Transform\n",
    "Secrets Engine](https://learn.hashicorp.com/tutorials/vault/transform) to learn about the format preserving\n",
    "encryption (FPE) transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help and Reference\n",
    "\n",
    "- [Transform Secrets Engine (API)](https://www.vaultproject.io/api-docs/secret/transform)\n",
    "- [Transform Secrets Engine](https://www.vaultproject.io/docs/secrets/transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker stop postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pushd ../HashiStack && \\\n",
    "docker-compose down\n",
    "popd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker ps --format \"table {{.ID}}\\t{{.Image}}\\t{{.Names}}\\t{{.Ports}}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
